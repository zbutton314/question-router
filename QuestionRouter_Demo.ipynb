{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "QuestionRouter - Demo.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Setup"
      ],
      "metadata": {
        "id": "1xjmPq3QSjNR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CAdRcu2ERjIW",
        "outputId": "1ae2e00b-1633-44f6-aa18-d3aa973c5aae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "import joblib\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "# from tensorflow.keras.models import Sequential\n",
        "# from tensorflow.keras.layers import Dense, Activation, Dropout\n",
        "# from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "drive.mount(\"/content/drive\")\n",
        "data_path = \"/content/drive/MyDrive/data/final_project/\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Functions"
      ],
      "metadata": {
        "id": "zr5qmNdqShGl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_objects():\n",
        "  model = keras.models.load_model(f\"{data_path}model\")\n",
        "  matrix_title = joblib.load(f\"{data_path}matrix_title.pkl\")\n",
        "  matrix_body = joblib.load(f\"{data_path}matrix_body.pkl\")\n",
        "  tfidf = joblib.load(f\"{data_path}tfidf.pkl\")\n",
        "\n",
        "  return model, matrix_title, matrix_body, tfidf\n",
        "\n",
        "\n",
        "def process_text(text):\n",
        "    text = re.sub(\"[!\\\"#$%&'()*+,-.\\/:;<=>?@\\[\\]^_`{|}~]\", \" \", text) # Punctuation\n",
        "    text = text.lower()\n",
        "\n",
        "    stop = stopwords.words('english')\n",
        "    text = ' '.join([word for word in text.split() if word not in stop]) # Stopwords\n",
        "\n",
        "    return text\n",
        "\n",
        "\n",
        "def predict_tag(title, body, tag=\"\"):\n",
        "  X_pred = pd.DataFrame({\"title\": title, \"body\": body}, index=[0])\n",
        "  X_pred['body_proc'] = X_pred['body'].apply(process_text)\n",
        "  X_pred['title_proc'] = X_pred['title'].apply(process_text)\n",
        "\n",
        "  X_body = pd.DataFrame(matrix_body.transform(X_pred[\"body_proc\"]).toarray())\n",
        "  X_body.columns = [f\"X_body_{i}\" for i in X_body.columns]\n",
        "\n",
        "  X_title = pd.DataFrame(matrix_title.transform(X_pred[\"title_proc\"]).toarray())\n",
        "  X_title.columns = [f\"X_title_{i}\" for i in X_title.columns]\n",
        "\n",
        "  X_pred = pd.concat([X_pred, X_body, X_title], axis=1)\n",
        "\n",
        "  x_cols = [col for col in X_pred.columns if \"X_\" in col]\n",
        "  X_tfidf = tfidf.transform(X_pred[x_cols]).toarray()\n",
        "\n",
        "  y_cols = [\"c\", \"c#\", \"c++\", \"html\", \"java\", \"javascript\", \"php\", \"python\", \"r\", \"sql\"]\n",
        "  y_pred = pd.DataFrame(model.predict(X_tfidf), columns=y_cols)\n",
        "  pred_tag = y_pred.apply(lambda x: y_pred.columns[x.argmax()], axis=1).iloc[0]\n",
        "\n",
        "  print(f\"Predicted Tag: {pred_tag}\")\n",
        "\n",
        "  if tag != \"\":\n",
        "    print(f\"Actual Tag: {tag}\")\n",
        "\n",
        "  return pred_tag\n",
        "\n",
        "\n",
        "def model_demo():\n",
        "  title = input(\"Title: \")\n",
        "  body = input(\"Body: \")\n",
        "  print(\"---\")\n",
        "  print(\"---\")\n",
        "  print(\"---\")\n",
        "  pred_tag = predict_tag(title, body)"
      ],
      "metadata": {
        "id": "BYDswkUDRnnS"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prepare Environment"
      ],
      "metadata": {
        "id": "8P9z43S1SlNw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model, matrix_title, matrix_body, tfidf = load_objects()"
      ],
      "metadata": {
        "id": "aY2GWFtbRnki"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Demo"
      ],
      "metadata": {
        "id": "Z9MLO101S26Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_demo()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YXnxRahnS2pn",
        "outputId": "7f5815d7-56d2-4e50-c1ca-941061b23dbc"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Title: How to group in Pandas query\n",
            "Body: Not sure how to get a sum per group. I can get it to work in SQL but not Pandas.\n",
            "---\n",
            "---\n",
            "---\n",
            "Predicted Tag: python\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "iBLKcxG5Rnhv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "DOWZvZiNRnfB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "KJSLa9yARnb_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "7lIoFMToRnZA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Xq3-6UIARnWg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "VqeA9E1ZRnTv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}